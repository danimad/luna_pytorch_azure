{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: create B2 cell for loading datasets into B2 storage, and link to it from here\n",
    "    for example this dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.4.11'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import conda\n",
    "conda.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.1 Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV writer from: https://stackoverflow.com/questions/45978295/saving-a-downloaded-csv-file-using-python\n",
    "import requests\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "\n",
    "data_dir = 'data'\n",
    "file_name = 'winequality-white.csv'\n",
    "data = os.path.join(data_dir, file_name)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "request = requests.get(url)\n",
    "\n",
    "if not os.path.exists(data):\n",
    "    with open(data, 'w') as file:\n",
    "        writer = csv.writer(file)\n",
    "        reader = csv.reader(request.text.splitlines())\n",
    "\n",
    "        for row in reader:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "\n",
    "wineq_numpy = np.loadtxt(data,\n",
    "                         dtype=np.float32, delimiter=\";\",\n",
    "                         skiprows=1)\n",
    "\n",
    "wineq_numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fixed acidity', 'volatile acidity', 'citric acid',\n",
       "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
       "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol',\n",
       "       'quality'], dtype='<U20')"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize/map info: https://stackoverflow.com/questions/9236926/concatenating-two-one-dimensional-numpy-arrays\n",
    "wineq_header = np.genfromtxt(data,\n",
    "                             dtype=np.dtype('U'),\n",
    "                             delimiter=\";\",\n",
    "                             autostrip=True,\n",
    "                             max_rows=1)\n",
    "\n",
    "wineq_header = np.array([header.strip('\"') for header in wineq_header])\n",
    "\n",
    "wineq_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq_header.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq_numpy.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "\n",
    "wineq.type() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4898, 12])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wineq[:, :-1]\n",
    "target = wineq[:, -1].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 4898x10]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10) \n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_var = torch.var(data, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = (data - data_mean) / torch.sqrt(data_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad = data[torch.le(target, 3).long()]\n",
    "data_good = data[torch.ge(target, 7).long()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column                       mean\n",
      "fixed acidity              6.9971\n",
      "volatile acidity           0.2701\n",
      "citric acid                0.3599\n",
      "residual sugar            20.6227\n",
      "chlorides                  0.0450\n",
      "free sulfur dioxide       44.8734\n",
      "total sulfur dioxide     169.8448\n",
      "density                    1.0010\n",
      "pH                         3.0012\n",
      "sulphates                  0.4501\n",
      "alcohol                    8.8033\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# string formating: https://docs.python.org/3/tutorial/inputoutput.html\n",
    "print(\"{:<22} {:>10}\".format(\"column\", \"mean\"))\n",
    "for i in itertools.zip_longest(wineq_header[:-1], torch.mean(data_bad, dim=0).numpy()):\n",
    "    print(\"{:<22} {:10.4f}\".format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column                       mean\n",
      "fixed acidity              6.8486\n",
      "volatile acidity           0.2765\n",
      "citric acid                0.3557\n",
      "residual sugar            16.5668\n",
      "chlorides                  0.0459\n",
      "free sulfur dioxide       38.2911\n",
      "total sulfur dioxide     161.7762\n",
      "density                    0.9995\n",
      "pH                         3.0649\n",
      "sulphates                  0.4586\n",
      "alcohol                    8.9518\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<22} {:>10}\".format(\"column\", \"mean\"))\n",
    "for i in itertools.zip_longest(wineq_header[:-1], torch.mean(data_good, dim=0).numpy()):\n",
    "    print(\"{:<22} {:10.4f}\".format(i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avr res sugar bad:       7.0545\n",
      "avr res sugar good:      6.0577\n",
      "threshold:               6.5561\n"
     ]
    }
   ],
   "source": [
    "residual_sugar = data[:,3]\n",
    "\n",
    "average_residual_sugar_bad = residual_sugar[torch.le(target, 5)].mean()\n",
    "\n",
    "average_residual_sugar_good = residual_sugar[torch.gt(target, 5)].mean()\n",
    "\n",
    "residual_sugar_threshold = 0.5 * (average_residual_sugar_good + average_residual_sugar_bad)\n",
    "\n",
    "print('avr res sugar bad: {:12.4f}'.format(average_residual_sugar_bad))\n",
    "print('avr res sugar good: {:11.4f}'.format(average_residual_sugar_good))\n",
    "print('threshold: {:20.4f}'.format(residual_sugar_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_quality = torch.lt(residual_sugar, residual_sugar_threshold)\n",
    "\n",
    "known_quality = torch.gt(target, 5)\n",
    "\n",
    "n_matches = torch.sum(known_quality * predicted_quality)\n",
    "\n",
    "n_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.2 Time Series\n",
    "\n",
    "Data from: https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip download from: https://stackoverflow.com/questions/9419162/download-returned-zip-file-from-url?noredirect=1\n",
    "import requests, zipfile, io\n",
    "\n",
    "data_dir = 'data/bikes'\n",
    "bike_file = 'hour.csv'\n",
    "bike_data = os.path.join(data_dir, bike_file)\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "bike_zip_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip\"\n",
    "\n",
    "req = requests.get(bike_zip_url)\n",
    "zipfile = zipfile.ZipFile(io.BytesIO(req.content))\n",
    "zipfile.extractall(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "     1.0000      1.0000      1.0000  ...       3.0000     13.0000     16.0000\n",
       "     2.0000      1.0000      1.0000  ...       8.0000     32.0000     40.0000\n",
       "     3.0000      1.0000      1.0000  ...       5.0000     27.0000     32.0000\n",
       "                ...                   ⋱                   ...                \n",
       " 17377.0000     31.0000      1.0000  ...       7.0000     83.0000     90.0000\n",
       " 17378.0000     31.0000      1.0000  ...      13.0000     48.0000     61.0000\n",
       " 17379.0000     31.0000      1.0000  ...      12.0000     37.0000     49.0000\n",
       "[torch.FloatTensor of size 17379x17]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bikes_numpy = np.loadtxt(bike_data,\n",
    "                         dtype=np.float32,\n",
    "                         delimiter=\",\",\n",
    "                         skiprows=1,\n",
    "                         converters={1: lambda x: float(x[8:10])}\n",
    "                        )\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['instant', 'dteday', 'season', 'yr', 'mnth', 'hr', 'holiday',\n",
       "       'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum',\n",
       "       'windspeed', 'casual', 'registered', 'cnt'], dtype='<U10')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_header = np.genfromtxt(bike_data,\n",
    "                             dtype=np.dtype('U'),\n",
    "                             delimiter=\",\",\n",
    "                             autostrip=True,\n",
    "                             max_rows=1)\n",
    "\n",
    "bikes_header = np.array([header.strip('\"') for header in bikes_header])\n",
    "\n",
    "bikes_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['instant', 'dteday', 'season', ..., 'casual', 'registered',\n",
       "        'cnt'],\n",
       "       ['1', '2011-01-01', '1', ..., '3', '13', '16'],\n",
       "       ['2', '2011-01-01', '1', ..., '8', '32', '40'],\n",
       "       ...,\n",
       "       ['17377', '2012-12-31', '1', ..., '7', '83', '90'],\n",
       "       ['17378', '2012-12-31', '1', ..., '13', '48', '61'],\n",
       "       ['17379', '2012-12-31', '1', ..., '12', '37', '49']], dtype='<U10')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_header_nc = np.loadtxt(bike_data,\n",
    "                             dtype=np.dtype('U'),\n",
    "                             delimiter=\",\",\n",
    "                             )\n",
    "\n",
    "bikes_header_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sorted_row_idxs = torch.sort(bikes[:, 0], dim=0)\n",
    "\n",
    "bikes = bikes[sorted_row_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 1)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 2: size '[-1 x 24 x 17]' is invalid for input with 295443 elements at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/THStorage.c:37",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-a1a203be8a17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdaily_bikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbikes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbikes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: size '[-1 x 24 x 17]' is invalid for input with 295443 elements at /Users/soumith/minicondabuild3/conda-bld/pytorch_1518385717421/work/torch/lib/TH/THStorage.c:37"
     ]
    }
   ],
   "source": [
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-d817b8b69ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbikes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "bikes.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17379, 17])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_bikes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-5b39b3a8d27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdaily_bikes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'daily_bikes' is not defined"
     ]
    }
   ],
   "source": [
    "daily_bikes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 Text\n",
    "\n",
    "### Character-level encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV writer from: https://stackoverflow.com/questions/45978295/saving-a-downloaded-csv-file-using-python\n",
    "import requests\n",
    "import os.path\n",
    "\n",
    "text_url = \"http://www.gutenberg.org/files/1342/1342-0.txt\"\n",
    "\n",
    "data_dir = 'data'\n",
    "text_filename = '1342-0.txt'\n",
    "text_path = os.path.join(data_dir, text_filename)\n",
    "\n",
    "request = requests.get(text_url)\n",
    "\n",
    "text_data = request.text\n",
    "\n",
    "if not os.path.exists(text_path):\n",
    "    with open(text_path, 'w') as file:\n",
    "        file.write(text_data)\n",
    "        file.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/1342-0.txt') as f:\n",
    "    text_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,l'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if\n",
    "                  unicodedata.category(c) != 'Mn' and c in all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,l'\""
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sl.'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode_to_ascii(\"sl0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = text_data.split('\\n')\n",
    "line = lines[200]\n",
    "#line = '“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 57])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.zeros(len(line), n_letters)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = all_letters.find(letter)\n",
    "    tensor[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 1, 57])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.unsqueeze(tensor, 1)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-level encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7261"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = text_data.lower().replace('\\n', ' ').split()\n",
    "punctuation = '.,;:\"!?”“_-'\n",
    "\n",
    "all_words = {word.strip(punctuation): i for (i, word) in\n",
    "            enumerate(all_words)}\n",
    "\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“Impossible, Mr. Bennet, impossible, when I am not acquainted with him'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impossible',\n",
       " 'mr',\n",
       " 'bennet',\n",
       " 'impossible',\n",
       " 'when',\n",
       " 'i',\n",
       " 'am',\n",
       " 'not',\n",
       " 'acquainted',\n",
       " 'with',\n",
       " 'him']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = text_data.split('\\n')\n",
    "\n",
    "line = lines[200]\n",
    "\n",
    "words_in_line = [word.strip(punctuation) for word in line.lower().split(' ')]\n",
    "\n",
    "words_in_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 7261])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.zeros(len(words_in_line), len(all_words))\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 116803 is out of range for dimension 0 (of size 7261)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-280-69f06fd2b52c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_in_line\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mword_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 116803 is out of range for dimension 0 (of size 7261)"
     ]
    }
   ],
   "source": [
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = all_words[word]\n",
    "    tensor[i][word_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 7261])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = tensor.unsqueeze(1)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.4 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/esc-50/1-100038-A-14.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-92811a996445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwaveform_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/io/wavfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(filename, mmap)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mmmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/esc-50/1-100038-A-14.wav'"
     ]
    }
   ],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "import os\n",
    "\n",
    "audio_dir = 'data/esc-50/'\n",
    "audio_file = '1-100038-A-14.wav'\n",
    "audio = os.path.join(audio_dir, audio_file)\n",
    "\n",
    "freq, waveform_arr = wavfile.read(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44100"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -388, -3387, -4634, ...,  2289,  1327,    90], dtype=int16)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = torch.from_numpy(waveform_arr).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "f_arr, t_arr, sp_arr = signal.spectrogram(waveform_arr, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 4.3517e+00  1.4044e+00  2.7865e-04  ...   1.3261e-01  8.4661e-03  7.7487e+00\n",
       " 4.4579e+01  3.3186e+00  5.3582e+00  ...   2.7802e+01  1.2889e+01  1.6912e+01\n",
       " 9.5455e+01  2.9964e+01  7.6881e+01  ...   2.8018e+01  2.5155e+01  1.6094e+02\n",
       "                ...                   ⋱                   ...                \n",
       " 2.3361e-06  1.3716e-06  1.1413e-05  ...   3.5789e-06  4.2816e-06  6.9388e-06\n",
       " 2.1429e-06  1.4071e-06  9.2230e-07  ...   7.9787e-07  1.8314e-06  1.0062e-06\n",
       " 5.5598e-06  3.1114e-06  1.1163e-05  ...   6.2336e-07  6.3296e-07  2.6184e-06\n",
       "[torch.FloatTensor of size 129x984]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = torch.from_numpy(sp_arr)\n",
    "sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.5 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.4.11\n",
      "  latest version: 4.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/danimad/anaconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - imageio\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2018.1.18          |           py36_0         143 KB  conda-forge\n",
      "    anaconda-custom            |   py36ha4fed55_0           6 KB\n",
      "    conda-4.3.34               |           py36_0         515 KB  conda-forge\n",
      "    openssl-1.0.2n             |                0         3.3 MB  conda-forge\n",
      "    imageio-2.3.0              |           py36_0         3.3 MB  conda-forge\n",
      "    ca-certificates-2018.1.18  |                0         141 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.3 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    anaconda:        5.1.0-py36_2          --> custom-py36ha4fed55_0            \n",
      "    ca-certificates: 2017.08.26-ha1e5d58_0 --> 2018.1.18-0           conda-forge\n",
      "    certifi:         2018.1.18-py36_0      --> 2018.1.18-py36_0      conda-forge\n",
      "    imageio:         2.2.0-py36h5e01289_0  --> 2.3.0-py36_0          conda-forge\n",
      "    openssl:         1.0.2n-hdbc3d79_0     --> 1.0.2n-0              conda-forge\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "    conda:           4.4.11-py36_0         --> 4.3.34-py36_0         conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "certifi 2018.1.18: ##################################################### | 100% \n",
      "anaconda custom: ####################################################### | 100% \n",
      "conda 4.3.34: ########################################################## | 100% \n",
      "openssl 1.0.2n: ######################################################## | 100% \n",
      "imageio 2.3.0: ######################################################### | 100% \n",
      "ca-certificates 2018.1.18: ############################################# | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "import os\n",
    "\n",
    "data_dir = 'data'\n",
    "img_file = 'dog.jpg'\n",
    "image = os.path.join(data_dir, img_file)\n",
    "\n",
    "img_arr = imageio.imread(image)\n",
    "\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "img = torch.from_numpy(img_arr)\n",
    "out = torch.transpose(img, 0, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
